-------------------------------------
(learning GANs)

- GAN for CELEB faces from Pytorch tutorials. 
	(convolutional, batch normalization)
	(strange: the noise vector within the channels...)
	(tested also a linear version)

- GAN for MNIST digits (myself)
	- same as (1)
	- flat, with a flat noise vector

- Conditional GAN for MNIST (myself)

- Inpainting faces with a Context Encoder

-------------------------------------
20-10-2021: GAN for pose generation. Input/output = normalized keypoints from H36M_ECCV18_FILTERED.


31-10-2021: Tested the ouput keypoints with smplify-x, it seems to work! :-)

POTENTIAL IMPROVEMENTS: 
	- Normalize and center keypoints? 
	- Better prefiltering for the dataset? 
	- Explore deep learning for low dimensional data: overfitting problem
	- Alernatives: Bayesian deep neural (no overfit), radial basis function network
	- Alternative representation of the data: heatmaps, images, etc.  
-------------------------------------
01-10-2021: Design of the pose inpainting network

	1) From H36M generate of images with occlusions
	2) With openpose generate pairs of (keypoints, keypoints with occlusions)
	3) Network (similar to the Context Encoder:

	keypoints with occlusions -> GENERATOR -> full keypoints -> use the originals where condfident? = fake keypoints
                                                        
	(fake keypoints, , keypoints with occlusions) -> DISCRIMINATOR 
	and also
	(keypoints, keypoints with occlusions)

	WARNING: The keypoints with occlusions generated by openpose may be globally different?
-------------------------------------
08-11-2021: Testing of the pose inpainting network

	WARNING: The normalization takes the spine index, why if it's not present?
-------------------------------------
18-11-2021: 
	- Problem 1: optical flow in video sequences. 
		- May not be necessary but
		- Generating animations may be more interesting
			- [1] Human Action Generation with Generative Adversarial Networks
			- [2] Generative Model for Skeletal Human Movements Based on Conditional DC-GAN Applied to Pseudo-Images
	- Problem 2: How to evaluate?
		- Definie own metric like FID
		- "FPD" Which "task" model? skeleton based action recognition. scGCN seems ok	
		- Problem, is for sequences
		- I have to visualize the poses anyway, to evaluate the metric
--------------------------------------
Found this: 
	3D Human Pose Estimaiton with Lifting Transformer
	file:///Users/rtous/Downloads/LiftTrans_arXiv.pdf

HEy why not using a video-vased 2D pose detector?
	Combining detection and tracking for human pose estimation in videos
	https://arxiv.org/pdf/2003.13743v1.pdf
--------------------------------------
22-11-2021:
	- recordem objectiu: COMPLETAR VIDEOS AMB IMATGE PARCIAL DEL COS
	- Cal que sigui compatible amb SMPLIFY-X?
--------------------------------------
19-12-2021:
	- He substituit el dataset per un que fa crop automàticament de parts
	- He canviat el bone de referencia, ara agafo un del cap. La selecció de la referencia depenent del cas ha donat problemes ja que agafa una diferent pel cropped que pel groundtruth. 
	- Resultats força bons, però falten més dades.
	- TODO: Ampliar els crops que es fan (un braç, etc.)
	- TODO: Més dades? COCO? ÉS LA CLAU
	- IDEA: t-SNE
	- TODO: Fer el 3D lifting i veure si millora
	- TODO: Algunes parts que es mostren al "debug_input" no es mostren al "debug". Caldria veure per què.
	- TODO: Cal revisar alguns criteris:
		- (sempre) El threshold per mantenir o substituir joints
		- (al generar el dataset) Mirar la confidence abans d'acceptar el bone de referència
-----------------------------------------------
25-01-2021
	- He preparat el dataset de COCO
	- He començat a entrenar a asterix
	- Començo per entrenar amb ECCV2018, hi ha moltes dades! però en acabar la primera epoch (unes 3-4 hores) peta:

**************************************************************
[0/100][29000/?]	Loss_D: 1.3104	Loss_G: 0.9758	D(x): 0.5982	D(G(z)): 0.4730 / 0.4090
Shape of fake:  torch.Size([64, 50])
scaleFactor= 21.492952555903354
keypoints_cropped.shape =  torch.Size([50])
testMany()...
testMany() finished.
Closed scandirIterator.
Closed scandirIterator.
Closed scandirIterator.
Closed scandirIterator.
Traceback (most recent call last):
  File "test12_poseCompletion4_CGAN_v3_justpatch_charade.py", line 573, in <module>
    batch_of_fake_original = netG(batch_of_keypoints_cropped, noise)
  File "/home/users/jpoveda/partial2D/myvenv/lib/python3.7/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "test12_poseCompletion4_CGAN_v3_justpatch_charade.py", line 262, in forward
    return self.main(input)
  File "/home/users/jpoveda/partial2D/myvenv/lib/python3.7/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/users/jpoveda/partial2D/myvenv/lib/python3.7/site-packages/torch/nn/modules/container.py", line 92, in forward
    input = module(input)
  File "/home/users/jpoveda/partial2D/myvenv/lib/python3.7/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/users/jpoveda/partial2D/myvenv/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py", line 81, in forward
    exponential_average_factor, self.eps)
  File "/home/users/jpoveda/partial2D/myvenv/lib/python3.7/site-packages/torch/nn/functional.py", line 1652, in batch_norm
    raise ValueError('Expected more than 1 value per channel when training, got input size {}'.format(size))
ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 512])

PROBLEM: Crashes before changing epoch. Don't know why
SOLVED: Limit number of batches to 25000

--------------------------------------
01-02-2022: 
- DONE: Training only with COCO gives bad results, TODO: more epochs
- DONE: Setup training in asterix complete
- Long training of ECCV18 improves but at certain point it stops improving
- DONE: Tensorboard complete, it shows that longer trainings will not improve
- TODO: training with COCO+ECCV18
- CHANGED THE MODEL! added regression (pixel loss) as in the context encoder
- QUESTION: Maybe the remaining charade keypoints are not good. Check with artificiall cropped (hollywood dataset from ECCV18)
- DONE: Created a small test set from hollywood (ECCV18). Tested! meshes seem ok, some poses are not processed. Scale problems
- INFO: Seems that prediction of real values gives problems to DL. Maybe I can try heatmaps or a VAE-GAN, or a Wasserstein GAN
--------------------------------------
02-02-2022: 
- Testing Frechet distance. 
- Tried 3d_pose_baseline to get intermediate embedings but complex.
- I don't need that, frechet is computationally costly but I work with 
low dimensional data
- It seems to work (FPD.py)
- Approach
	- Select baseline dataset
	- Compare slices of baseline data against dataset
	- Compare test dataset against dataset
	- Compare reconstructed test dataset againts dataset
- TODO! WARNING! I'm comparing with the confidence value!
--------------------------------------
08-02-2022: 
- TODO: The ECCV18OP dataset has many undetected poses, this is why it's so different from the ECCV18OP_crop_orig dataset. Maybe I should use the original ECCV18 dataset, but how to obtain the 2D poses? 
- Discovered project_point_radial in H36M software
--------------------------------------
1-02-2022: 
- DONE: Refactoring
- DONE: Generation of crop images on-the-fly
- DONE: Test H36M
- PROBLEM: H36M discriminator collapses. Also generator errors are strange.
	- Maybe inputs are too similar. Tried increassing buffer without success
--------------------------------------
14-03-2022: 
- Tried with heatmaps. PROBLEM: too slow (PENDING)
- DONE: Tried with only joints that are in H36M and openpose (15). Great
improvement of FPD!
- Tried with wasserstein GAN. Unstable training. FPD results seems ok but around 15000
--------------------------------------
20-04-2022: 
- Solved the speed problem with heatmaps (incresing the stride in the Discriminator?). But results still not good.
- Tried to start from a simple autoencoder. Everything seems to work
- Now try a simple DCGAN (using the decoder part of the autoencoder). 
- This is not working, trying to solve the problem
- Use tensorboard to display evolution
- PROBLEM: Discriminator goes to zero, not learning
- SOLUTION: cannot use a sigmoid layer and then binary cross entropy (BCE) loss. Remove sigmoid and use BCEWithLogitsLoss
https://github.com/soumith/ganhacks/issues/36
- Seems not to work...
- SOLVED! La DCGAN funciona si replico lo del faces. el noise són 100 heatmaps de 1x1. He copiat el seu Generator i voilà...
---------------------------------------------
27-04-2022
- Trying now with the conditional GAN
- It does not work. One problem I see is that regression loss is almost zero.
- Found this: 
https://discuss.pytorch.org/t/mse-l2-loss-on-two-masked-images/28417/3
- pixel wise Euclidean loss
https://www.reddit.com/r/deeplearning/comments/ia8fec/survey_on_loss_for_heatmap_regression/
---------------------------------------------
28-04-2022

- I disabled the GAN and using just regression. Initially it didn't work
- Getting inspiration from my autoencoder I set normalize=True in the last downsample layer and it works! but it replicates the same output...
- I see that the autoencoder has normalize=True also in the last upsample layer... I tried it but does not make any difference
- I tried with more data buffer and... seems to work :-)

data/output/H36M/TEST/keypoints size=1000
FID: 11497.921
---------------------------------------------
29-04-2022
- Recapitulem. Sense heatmaps (epoch 4, step 12000) obtinc 5063.359. Amb heatmaps uns 8000 aprox. 
---------------------------------------------
25-07-2022
- Ja tinc el paper gairebé llest. 
- He tornat a fer proves amb ECCV18OP (resultat a ECCV18OP_FINAL)
- He hagut de crear un datasetBasic que agafés els keypoints tallats i guardats en comptes de tallar-los on-the-fly (com faig a H36M). Encara no sé per què no funciona.

WARNING: Veig que la normalització no la faig amb neck grandària 1??
WARNinG: Testing center at 0,0 i scaling a 1 
Sembla funcionar però dona un FD molt alt...


